{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/output/dogscats/'\n",
    "train_filenames = os.listdir(path+'train/')\n",
    "train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "x = ['train_cat', 'train_dog', 'test']\n",
    "y = [len(os.listdir(path+'train/cats/')), len(os.listdir(path+'train/dogs/')), len(os.listdir(path+'test_small/cats/'))]\n",
    "ax = sns.barplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain = os.listdir(path+'train/cats/')\n",
    "mytrain += os.listdir(path+'train/dogs/')\n",
    "myvalid = os.listdir(path+'valid/cats/')\n",
    "myvalid += os.listdir(path+'valid/dogs/')\n",
    "\n",
    "print len(mytrain), len(myvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain_cat = filter(lambda x:x[:3] == 'cat', mytrain)\n",
    "mytrain_dog = filter(lambda x:x[:3] == 'dog', mytrain)\n",
    "myvalid_cat = filter(lambda x:x[:3] == 'cat', myvalid)\n",
    "myvalid_dog = filter(lambda x:x[:3] == 'dog', myvalid)\n",
    "x = ['mytrain_cat', 'mytrain_dog', 'myvalid_cat', 'myvalid_dog']\n",
    "y = [len(mytrain_cat), len(mytrain_dog), len(myvalid_cat), len(myvalid_dog)]\n",
    "\n",
    "ax = sns.barplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def remove_and_create_class(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "    os.mkdir(dirname+'/cats')\n",
    "    os.mkdir(dirname+'/dogs')\n",
    "\n",
    "remove_and_create_class('mytrain')\n",
    "remove_and_create_class('myvalid')\n",
    "\n",
    "for filename in mytrain_cat:\n",
    "    os.symlink('output/output/dogscats/'+'train/cats/'+filename, 'mytrain/cats/'+filename)\n",
    "\n",
    "for filename in mytrain_dog:\n",
    "    os.symlink('output/output/dogscats/'+'train/dogs/'+filename, 'mytrain/dogs/'+filename)\n",
    "\n",
    "for filename in myvalid_cat:\n",
    "    os.symlink('output/output/dogscats/'+'valid/cats/'+filename, 'myvalid/cats/'+filename)\n",
    "\n",
    "for filename in myvalid_dog:\n",
    "    os.symlink('output/output/dogscats/'+'valid/dogs/'+filename, 'myvalid/dogs/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, add, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD,Adam,Adagrad\n",
    "from keras.utils.data_utils import get_file\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    " \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "image_size = (image_width, image_height)\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen1 = ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator1 = train_datagen1.flow_from_directory(\n",
    "        'mytrain1',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "train_datagen2 = ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "        'mytrain2',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "train_datagen3 = ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator3 = train_datagen3.flow_from_directory(\n",
    "        'mytrain3',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'myvalid',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(input_tensor=Input((224, 224, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "    \n",
    "print base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_features1 = np.zeros(shape=(7332, 7, 7, 512))\n",
    "train_labels1 = np.zeros(shape=(7332,2))\n",
    "batch_size = 16\n",
    "i = 0\n",
    "\n",
    "for inputs_batch, labels_batch in train_generator1 :\n",
    "    features_batch = base_model.predict(inputs_batch)\n",
    "    train_features1[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels1[i * batch_size : (i + 1) * batch_size] = to_categorical(labels_batch)\n",
    "    i += 1\n",
    "    if i * batch_size >= 7332:\n",
    "        break\n",
    "         \n",
    "\n",
    "train_features1 = np.reshape(train_features1, (7332, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features2 = np.zeros(shape=(7334, 7, 7, 512))\n",
    "train_labels2 = np.zeros(shape=(7334,2))\n",
    "batch_size = 16\n",
    "i = 0\n",
    "\n",
    "for inputs_batch, labels_batch in train_generator2 :\n",
    "    features_batch = base_model.predict(inputs_batch)\n",
    "    train_features2[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels2[i * batch_size : (i + 1) * batch_size] = to_categorical(labels_batch)\n",
    "    i += 1\n",
    "    if i * batch_size >= 7334:\n",
    "        break\n",
    "         \n",
    "\n",
    "train_features2 = np.reshape(train_features2, (7334, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features3 = np.zeros(shape=(7334, 7, 7, 512))\n",
    "train_labels3 = np.zeros(shape=(7334,2))\n",
    "batch_size = 16\n",
    "i = 0\n",
    "\n",
    "for inputs_batch, labels_batch in train_generator3 :\n",
    "    features_batch = base_model.predict(inputs_batch)\n",
    "    train_features3[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels3[i * batch_size : (i + 1) * batch_size] = to_categorical(labels_batch)\n",
    "    i += 1\n",
    "    if i * batch_size >= 7334:\n",
    "        break\n",
    "         \n",
    "\n",
    "train_features3 = np.reshape(train_features3, (7334, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features = np.zeros(shape=(2000, 7, 7, 512))\n",
    "valid_labels = np.zeros(shape=(2000,2))\n",
    "batch_size = 16\n",
    "i = 0\n",
    "\n",
    "for inputs_batch, labels_batch in validation_generator :\n",
    "    features_batch = base_model.predict(inputs_batch)\n",
    "    valid_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    valid_labels[i * batch_size : (i + 1) * batch_size] = to_categorical(labels_batch)\n",
    "    i += 1\n",
    "    if i * batch_size >= 2000:\n",
    "        break\n",
    "        \n",
    "         \n",
    "\n",
    "valid_features = np.reshape(valid_features, (2000, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "image_size = (image_width, image_height)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'mytest-lbl',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_features = np.zeros(shape=(1000, 7, 7, 512))\n",
    "test_labels = np.zeros(shape=(1000,))\n",
    "batch_size = 20\n",
    "i = 0\n",
    "\n",
    "for inputs_batch,labels_batch in test_generator :\n",
    "    features_batch = base_model.predict(inputs_batch)\n",
    "    test_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= 1000:\n",
    "        break\n",
    "   \n",
    "\n",
    "test_features = np.reshape(test_features, (1000, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = model.get_weights()\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_vgg_jia.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"initial_weights_vgg_jia.h5\")\n",
    "\n",
    "json_file = open('model_vgg_jia.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model0 = model_from_json(loaded_model_json)\n",
    "model0.load_weights(\"initial_weights_vgg_jia.h5\")\n",
    "model0.compile(optimizer=SGD(lr=0.002),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h=model0.fit(train_features1, train_labels1, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model0.save(\"sgd_vgg_1_jia.h5\")\n",
    "\n",
    "model1 = model_from_json(loaded_model_json)\n",
    "model1.load_weights(\"sgd_vgg_1_jia.h5\")\n",
    "model1.compile(optimizer=SGD(lr=0.002),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h1=model1.fit(train_features2, train_labels2, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model1.save(\"sgd_vgg_2_jia.h5\")\n",
    "\n",
    "model2 = model_from_json(loaded_model_json)\n",
    "model2.load_weights(\"sgd_vgg_2_jia.h5\")\n",
    "model2.compile(optimizer=SGD(lr=0.002),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h2=model2.fit(train_features3, train_labels3, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model2.save(\"sgd_vgg_3_jia.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_full = load_model('sgd_vgg_1.h5')\n",
    "model0 = load_model('sgd_vgg_1_jia.h5')\n",
    "model1 = load_model('sgd_vgg_2_jia.h5')\n",
    "model2 = load_model('sgd_vgg_3_jia.h5')\n",
    "\n",
    "test_full_labels = model_full.predict(test_features)\n",
    "test0_labels = model0.predict(test_features)\n",
    "test1_labels = model1.predict(test_features)\n",
    "test2_labels = model2.predict(test_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['SGD1', 'SGD2', 'SGD3']\n",
    "tst_loss_run_sgd = [model0.evaluate(test_features,test_actual)[1],model1.evaluate(test_features,test_actual)[1],model2.evaluate(test_features,test_actual)[1]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "#plt.scatter(labels,tst_loss_run_sgd)\n",
    "plt.plot(labels, tst_loss_run_sgd, '-o')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_loss_fullsgd_sgd123 = [np.linalg.norm((test2_labels - test0_labels)),np.linalg.norm((test2_labels - test1_labels)),np.linalg.norm((test2_labels - test2_labels))] #,np.linalg.norm((test2_labels - test8_labels)),np.linalg.norm((test5_labels - test8_labels)) ]\n",
    "labels = ['SGD1-SGD', 'SGD2-SGD', 'SGD3-SGD']\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "#plt.scatter(labels,dist_loss_fullsgd_sgd123)\n",
    "plt.plot(labels, dist_loss_fullsgd_sgd123, '-o')\n",
    "plt.ylabel('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "batch_size=16\n",
    "model0 = model_from_json(loaded_model_json)\n",
    "model0.load_weights(\"initial_weights_vgg.h5\")\n",
    "model0.compile(optimizer=Adam(lr=0.002, beta_1=0.9, beta_2=0.999, decay=0.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h=model0.fit(train_features1, train_labels1, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model0.save(\"adam_vgg_1_jia.h5\")\n",
    "\n",
    "model1 = model_from_json(loaded_model_json)\n",
    "model1.load_weights(\"adam_vgg_1_jia.h5\")\n",
    "model1.compile(optimizer=Adam(lr=0.002, beta_1=0.9, beta_2=0.999, decay=0.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h1=model1.fit(train_features2, train_labels2, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model1.save(\"adam_vgg_2_jia.h5\")\n",
    "\n",
    "model2 = model_from_json(loaded_model_json)\n",
    "model2.load_weights(\"adam_vgg_2_jia.h5\")\n",
    "model2.compile(optimizer=Adam(lr=0.002, beta_1=0.9, beta_2=0.999, decay=0.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h2=model2.fit(train_features3, train_labels3, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model2.save(\"adam_vgg_3_jia.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_full = load_model('adam_vgg_4.h5')\n",
    "model0 = load_model('adam_vgg_1_jia.h5')\n",
    "model1 = load_model('adam_vgg_2_jia.h5')\n",
    "model2 = load_model('adam_vgg_3_jia.h5')\n",
    "\n",
    "test_full_labels = model_full.predict(test_features)\n",
    "test0_labels = model0.predict(test_features)\n",
    "test1_labels = model1.predict(test_features)\n",
    "test2_labels = model2.predict(test_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_loss_fullsgd_adm123 = [np.linalg.norm((test2_labels - test0_labels)),np.linalg.norm((test2_labels - test1_labels)),np.linalg.norm((test2_labels - test2_labels))] #,np.linalg.norm((test2_labels - test8_labels)),np.linalg.norm((test5_labels - test8_labels)) ]\n",
    "labels = ['ADM1-ADM', 'ADM2-ADM', 'ADM3-ADM']\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "#plt.scatter(labels,dist_loss_fullsgd_adm123)\n",
    "plt.plot(labels, dist_loss_fullsgd_adm123, '-o')\n",
    "plt.ylabel('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ADM1', 'ADM2', 'ADM3']\n",
    "tst_loss_run_adm = [model0.evaluate(test_features,test_actual)[1],model1.evaluate(test_features,test_actual)[1],model2.evaluate(test_features,test_actual)[1]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "#plt.scatter(labels,tst_loss_run_adm)\n",
    "plt.plot(labels, tst_loss_run_adm, '-o')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adagrad\n",
    "batch_size=16\n",
    "model0 = model_from_json(loaded_model_json)\n",
    "model0.load_weights(\"initial_weights_vgg.h5\")\n",
    "model0.compile(optimizer=Adagrad(lr=0.002, decay=0.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h=model0.fit(train_features1, train_labels1, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model0.save(\"adag_vgg_1_jia.h5\")\n",
    "\n",
    "model1 = model_from_json(loaded_model_json)\n",
    "model1.load_weights(\"adag_vgg_1_jia.h5\")\n",
    "model1.compile(optimizer=Adagrad(lr=0.002, decay=0.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h1=model1.fit(train_features2, train_labels2, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model1.save(\"adag_vgg_2_jia.h5\")\n",
    "\n",
    "model2 = model_from_json(loaded_model_json)\n",
    "model2.load_weights(\"adag_vgg_2_jia.h5\")\n",
    "model2.compile(optimizer=Adagrad(lr=0.002, decay=0.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "h2=model2.fit(train_features3, train_labels3, batch_size=batch_size, epochs=50, validation_data=(valid_features, valid_labels))\n",
    "model2.save(\"adag_vgg_3_jia.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_full = load_model('adag_vgg_7.h5')\n",
    "#model0 = load_model('adag_vgg_1_jia.h5')\n",
    "#model1 = load_model('adag_vgg_2_jia.h5')\n",
    "#model2 = load_model('adag_vgg_3_jia.h5')\n",
    "\n",
    "test_full_labels = model_full.predict(test_features)\n",
    "test0_labels = model0.predict(test_features)\n",
    "test1_labels = model1.predict(test_features)\n",
    "test2_labels = model2.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_loss_fullsgd_adm123 = [np.linalg.norm((test2_labels - test0_labels)),np.linalg.norm((test2_labels - test1_labels)),np.linalg.norm((test2_labels - test2_labels))] #,np.linalg.norm((test2_labels - test8_labels)),np.linalg.norm((test5_labels - test8_labels)) ]\n",
    "labels = ['ADG1-ADG', 'ADG2-ADG', 'ADG3-ADG']\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "#plt.scatter(labels,dist_loss_fullsgd_adg123)\n",
    "plt.plot(labels, dist_loss_fullsgd_adm123, '-o')\n",
    "plt.ylabel('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ADG1', 'ADG2', 'ADG3']\n",
    "tst_loss_run_adm = [model0.evaluate(test_features,test_actual)[1],model1.evaluate(test_features,test_actual)[1],model2.evaluate(test_features,test_actual)[1]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "#plt.scatter(labels,tst_loss_run_adg)\n",
    "plt.plot(labels, tst_loss_run_adm, '-o')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
